# Predicting Recidivism applying IRAC method

In this project, we will study the datasets released by ProPublica, a nonprofit organization based in New York City which aims to produce investigative journalism in the public interest. The datasets for this project consist of 4 parts (‘compas-scores-two-years.csv’, ‘compas-scores-two-years-violent.csv’, ‘cox-parsed.csv’ and ‘cox-violent-parsed.csv’). Those datasets consist of more than 10,000 criminal defendants in Broward County, Florida, who had been assessed with the COMPAS (which stands for Correctional Offender Management Profiling for Alternative Sanctions) screening system between 1st January 2013 and 31st December 2014. Based on the screening and assessment, the COMPAS software will generate several scores, which are used to quantify the risks of recidivism of a particular criminal defendant. There are more than 50 feature variables in the datasets, including the criminal defendants’ race, gender and age. Since these features are present in the datasets, we will examine if any machine bias in the algorithm, that is, any bias against certain group of people just because of their skin color or gender.

In addition, we will also focus on the legal and ethical concerns raised due to the usage of these features in the algorithm. Subsequently, we will apply the IRAC method to identify the legal issue which we think arises out of these facts, and any rule or policy we think is on point. Finally, we will apply the rule or policy to reach the final conclusion.

The following documents are provided in this repository:
  1. STD-0322A-Lee Jack Shiang-Project.docx: Word document for the project report
  2. STD-0322A-Lee Jack Shiang-Project.R: R codes for the project
  3. The 4 csv files: Datasets for this project
